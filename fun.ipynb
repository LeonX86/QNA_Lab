{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### markdown文本切块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def split_markdown_by_headers(input_file, output_dir):\n",
    "    \"\"\"\n",
    "    按照大标题（#开头）将Markdown文件切分成多个文件\n",
    "\n",
    "    Args:\n",
    "        input_file: 输入的Markdown文件路径\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    # 创建输出目录\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"创建目录: {output_dir}\")\n",
    "\n",
    "    # 读取Markdown文件内容\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 使用正则表达式查找所有以#开头的大标题\n",
    "    # 这里匹配的是以#开头，后面可能有空格，然后是标题文本，直到行尾\n",
    "    header_pattern = r'^# (.+)$'\n",
    "\n",
    "    # 查找所有匹配的标题\n",
    "    headers = re.finditer(header_pattern, content, re.MULTILINE)\n",
    "\n",
    "    # 记录所有标题的位置和名称\n",
    "    header_positions = []\n",
    "    for match in headers:\n",
    "        header_positions.append((match.start(), match.group(1).strip()))\n",
    "\n",
    "    # 如果没有找到标题，则将整个文件作为一个部分\n",
    "    if not header_positions:\n",
    "        output_file = os.path.join(output_dir, \"全部内容.md\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\"保存文件: {output_file}\")\n",
    "        return\n",
    "\n",
    "    # 处理文件开头到第一个标题之前的内容\n",
    "    if header_positions[0][0] > 0:\n",
    "        intro_content = content[:header_positions[0][0]].strip()\n",
    "        if intro_content:\n",
    "            output_file = os.path.join(output_dir, \"前言.md\")\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(intro_content)\n",
    "            print(f\"保存文件: {output_file}\")\n",
    "\n",
    "    # 处理每个标题及其内容\n",
    "    for i in range(len(header_positions)):\n",
    "        start_pos = header_positions[i][0]\n",
    "        title = header_positions[i][1]\n",
    "\n",
    "        # 确定内容的结束位置\n",
    "        if i < len(header_positions) - 1:\n",
    "            end_pos = header_positions[i + 1][0]\n",
    "        else:\n",
    "            end_pos = len(content)\n",
    "\n",
    "        # 提取当前标题的内容\n",
    "        section_content = content[start_pos:end_pos].strip()\n",
    "\n",
    "        # 创建安全的文件名\n",
    "        safe_title = re.sub(r'[\\\\/*?:\"<>|]', '_', title)\n",
    "        output_file = os.path.join(output_dir, f\"{safe_title}.md\")\n",
    "\n",
    "        # 写入文件\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(section_content)\n",
    "\n",
    "        print(f\"保存文件: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件路径\n",
    "    input_file = r\"c:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\无锡市社会救助帮扶惠民政策清单202420240125_1743663990.526207.md\"\n",
    "\n",
    "    # 输出目录\n",
    "    output_dir = r\"c:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\mddata\"\n",
    "\n",
    "    # 执行切分\n",
    "    split_markdown_by_headers(input_file, output_dir)\n",
    "    print(\"文件切分完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jsonl数据转表格展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理文件: C:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\data\\帮扶-1744006595791-sharegpt-2025-04-08.jsonl\n",
      "是否包含思考过程: 是\n",
      "已成功将数据保存到 C:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\data\\帮扶数据.xlsx\n",
      "处理完成!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_think_content(text):\n",
    "    \"\"\"从文本中提取<think>标签内的内容\"\"\"\n",
    "    think_pattern = r'<think>(.*?)</think>'\n",
    "    match = re.search(think_pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "\n",
    "def clean_response(text):\n",
    "    \"\"\"清除回答中的<think>标签及其内容\"\"\"\n",
    "    return re.sub(r'<think>.*?</think>\\s*', '', text, flags=re.DOTALL).strip()\n",
    "\n",
    "def jsonl_to_xlsx(input_file, output_file, include_think=False):\n",
    "    \"\"\"将JSONL文件转换为XLSX表格\"\"\"\n",
    "    # 读取JSONL文件\n",
    "    data = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # 跳过空行\n",
    "                continue\n",
    "            try:\n",
    "                json_obj = json.loads(line)\n",
    "                messages = json_obj.get('messages', [])\n",
    "                if len(messages) >= 2:\n",
    "                    question = messages[0].get('content', '')\n",
    "                    full_answer = messages[1].get('content', '')\n",
    "\n",
    "                    # 提取思考过程和清理后的回答\n",
    "                    think_content = extract_think_content(full_answer)\n",
    "                    clean_answer = clean_response(full_answer)\n",
    "\n",
    "                    if include_think:\n",
    "                        data.append({\n",
    "                            '问题': question,\n",
    "                            '答案': clean_answer,\n",
    "                            '思考过程': think_content\n",
    "                        })\n",
    "                    else:\n",
    "                        data.append({\n",
    "                            '问题': question,\n",
    "                            '答案': clean_answer\n",
    "                        })\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"警告: 无法解析JSON行: {line[:100]}...\")\n",
    "                continue\n",
    "\n",
    "    # 创建DataFrame并保存为XLSX\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"已成功将数据保存到 {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 配置参数\n",
    "    input_file = r\"C:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\data\\帮扶-1744006595791-sharegpt-2025-04-08.jsonl\"\n",
    "    output_file = r\"C:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\data\\帮扶数据.xlsx\"\n",
    "\n",
    "    # 是否包含思考过程的开关参数\n",
    "    include_think = True  # 设置为 True 包含思考过程，False 则不包含\n",
    "\n",
    "    # 执行转换\n",
    "    print(f\"开始处理文件: {input_file}\")\n",
    "    print(f\"是否包含思考过程: {'是' if include_think else '否'}\")\n",
    "\n",
    "    jsonl_to_xlsx(input_file, output_file, include_think)\n",
    "\n",
    "    print(\"处理完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_str 转 json_obj\n",
    " - 注意：Python展示json默认是单引号（python dict），而json的标准格式是双引号。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解析成功:\n",
      "{'Project_01': {'No.': 1, 'projectName': '项目名称', 'budgetInTenThousand': 50.8, 'projectDetails': '具体内容.'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict\n",
    "\n",
    "def robust_json_parser(raw_text: str) -> Dict:\n",
    "    # 清理非法前缀和杂项字符\n",
    "    cleaned_text = re.sub(r'^[^{]*{', '{', raw_text, flags=re.DOTALL)\n",
    "    # 处理中文冒号等非标符号\n",
    "    cleaned_text = cleaned_text.replace('：', ':')\n",
    "    # 移除尾部杂字符\n",
    "    cleaned_text = re.sub(r'}[^}]*$', '}', cleaned_text)\n",
    "    return json.loads(cleaned_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试数据\n",
    "    test_json = \"\"\"{\n",
    "        \"Project_01\" : {\n",
    "        \"No.\": 1,\n",
    "        \"projectName\": \"项目名称\",\n",
    "        \"budgetInTenThousand\": 50.8,\n",
    "        \"projectDetails\": \"具体内容.\"\n",
    "        }\n",
    "    }\"\"\"\n",
    "\n",
    "    # 执行测试\n",
    "    try:\n",
    "        result = robust_json_parser(test_json)\n",
    "        print(\"解析成功:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"解析失败: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
