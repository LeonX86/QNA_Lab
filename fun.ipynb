{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### markdown文本切块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def split_markdown_by_headers(input_file, output_dir):\n",
    "    \"\"\"\n",
    "    按照大标题（#开头）将Markdown文件切分成多个文件\n",
    "\n",
    "    Args:\n",
    "        input_file: 输入的Markdown文件路径\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    # 创建输出目录\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"创建目录: {output_dir}\")\n",
    "\n",
    "    # 读取Markdown文件内容\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 使用正则表达式查找所有以#开头的大标题\n",
    "    # 这里匹配的是以#开头，后面可能有空格，然后是标题文本，直到行尾\n",
    "    header_pattern = r'^# (.+)$'\n",
    "\n",
    "    # 查找所有匹配的标题\n",
    "    headers = re.finditer(header_pattern, content, re.MULTILINE)\n",
    "\n",
    "    # 记录所有标题的位置和名称\n",
    "    header_positions = []\n",
    "    for match in headers:\n",
    "        header_positions.append((match.start(), match.group(1).strip()))\n",
    "\n",
    "    # 如果没有找到标题，则将整个文件作为一个部分\n",
    "    if not header_positions:\n",
    "        output_file = os.path.join(output_dir, \"全部内容.md\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\"保存文件: {output_file}\")\n",
    "        return\n",
    "\n",
    "    # 处理文件开头到第一个标题之前的内容\n",
    "    if header_positions[0][0] > 0:\n",
    "        intro_content = content[:header_positions[0][0]].strip()\n",
    "        if intro_content:\n",
    "            output_file = os.path.join(output_dir, \"前言.md\")\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(intro_content)\n",
    "            print(f\"保存文件: {output_file}\")\n",
    "\n",
    "    # 处理每个标题及其内容\n",
    "    for i in range(len(header_positions)):\n",
    "        start_pos = header_positions[i][0]\n",
    "        title = header_positions[i][1]\n",
    "\n",
    "        # 确定内容的结束位置\n",
    "        if i < len(header_positions) - 1:\n",
    "            end_pos = header_positions[i + 1][0]\n",
    "        else:\n",
    "            end_pos = len(content)\n",
    "\n",
    "        # 提取当前标题的内容\n",
    "        section_content = content[start_pos:end_pos].strip()\n",
    "\n",
    "        # 创建安全的文件名\n",
    "        safe_title = re.sub(r'[\\\\/*?:\"<>|]', '_', title)\n",
    "        output_file = os.path.join(output_dir, f\"{safe_title}.md\")\n",
    "\n",
    "        # 写入文件\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(section_content)\n",
    "\n",
    "        print(f\"保存文件: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 输入文件路径\n",
    "    input_file = r\"c:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\无锡市社会救助帮扶惠民政策清单202420240125_1743663990.526207.md\"\n",
    "\n",
    "    # 输出目录\n",
    "    output_dir = r\"c:\\WorkFlow\\E\\Code\\Python\\QNA_Lab\\mddata\"\n",
    "\n",
    "    # 执行切分\n",
    "    split_markdown_by_headers(input_file, output_dir)\n",
    "    print(\"文件切分完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_str转json_obj\n",
    " - 注意：Python展示json默认是单引号（python dict），而json的标准格式是双引号。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解析成功:\n",
      "{'Project_01': {'No.': 1, 'projectName': '项目名称', 'budgetInTenThousand': 50.8, 'projectDetails': '具体内容.'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict\n",
    "\n",
    "def robust_json_parser(raw_text: str) -> Dict:\n",
    "    # 清理非法前缀和杂项字符\n",
    "    cleaned_text = re.sub(r'^[^{]*{', '{', raw_text, flags=re.DOTALL)\n",
    "    # 处理中文冒号等非标符号\n",
    "    cleaned_text = cleaned_text.replace('：', ':')\n",
    "    # 移除尾部杂字符\n",
    "    cleaned_text = re.sub(r'}[^}]*$', '}', cleaned_text)\n",
    "    return json.loads(cleaned_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试数据\n",
    "    test_json = \"\"\"{\n",
    "        \"Project_01\" : {\n",
    "        \"No.\": 1,\n",
    "        \"projectName\": \"项目名称\",\n",
    "        \"budgetInTenThousand\": 50.8,\n",
    "        \"projectDetails\": \"具体内容.\"\n",
    "        }\n",
    "    }\"\"\"\n",
    "\n",
    "    # 执行测试\n",
    "    try:\n",
    "        result = robust_json_parser(test_json)\n",
    "        print(\"解析成功:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"解析失败: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
